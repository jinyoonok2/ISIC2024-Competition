{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":108551,"sourceType":"modelInstanceVersion","modelInstanceId":68604,"modelId":93771}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport timm\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport h5py\nfrom io import BytesIO","metadata":{"execution":{"iopub.status.busy":"2024-09-06T08:33:09.973071Z","iopub.execute_input":"2024-09-06T08:33:09.973497Z","iopub.status.idle":"2024-09-06T08:33:09.980226Z","shell.execute_reply.started":"2024-09-06T08:33:09.973456Z","shell.execute_reply":"2024-09-06T08:33:09.978870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration dictionary\nconfig = {\n    'batch_size': 32,\n    'model_paths': {\n        'efficientnet_b3.ra2_in1k': '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/logs_effb3ra2in1k/epoch_19.pth',\n    },\n    'lightgbm_model_paths': ['/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/lightgbm/fold_1/best_model.txt',\n                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/lightgbm/fold_2/best_model.txt',\n                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/lightgbm/fold_3/best_model.txt',\n                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/lightgbm/fold_4/best_model.txt',\n                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/18/_kaggle_models/lightgbm/fold_5/best_model.txt'],\n    'submission_csv': 'submission.csv',\n}\n\n# Numeric columns\nnum_cols = [\n    'age_approx',\n    'clin_size_long_diam_mm',\n    'tbp_lv_A', 'tbp_lv_Aext',\n    'tbp_lv_B', 'tbp_lv_Bext',\n    'tbp_lv_C', 'tbp_lv_Cext',\n    'tbp_lv_H', 'tbp_lv_Hext',\n    'tbp_lv_L', 'tbp_lv_Lext',\n    'tbp_lv_areaMM2',\n    'tbp_lv_area_perim_ratio',\n    'tbp_lv_color_std_mean',\n    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL',\n    'tbp_lv_deltaLBnorm',\n    'tbp_lv_eccentricity',\n    'tbp_lv_minorAxisMM',\n    'tbp_lv_nevi_confidence',\n    'tbp_lv_norm_border',\n    'tbp_lv_norm_color',\n    'tbp_lv_perimeterMM',\n    'tbp_lv_radial_color_std_max',\n    'tbp_lv_stdL', 'tbp_lv_stdLExt',\n    'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n]\n\n# Non-numeric data found in columns\ncat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\", \"anatom_site_general\"]\n\n# Columns to drop based on comparison with test-metadata\ncolumns_to_drop = [\n    'iddx_3', 'iddx_2', 'iddx_5', 'iddx_full',\n    'tbp_lv_dnn_lesion_confidence', 'lesion_id',\n    'mel_mitotic_index', 'mel_thick_mm', 'iddx_1', 'iddx_4',\n    'image_type', 'attribution', 'copyright_license'\n]","metadata":{"execution":{"iopub.status.busy":"2024-09-06T08:33:09.982498Z","iopub.execute_input":"2024-09-06T08:33:09.983045Z","iopub.status.idle":"2024-09-06T08:33:09.995789Z","shell.execute_reply.started":"2024-09-06T08:33:09.982995Z","shell.execute_reply":"2024-09-06T08:33:09.994581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Dataset Class for HDF5 Images\nclass CustomDataset(Dataset):\n    def __init__(self, hdf5_file, isic_ids, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.transform = transform\n        self.fp_hdf = h5py.File(hdf5_file, mode=\"r\")\n\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        isic_id = self.isic_ids[idx]\n        # Corrected image loading using BytesIO\n        img = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n\n        if self.transform:\n            img = Image.fromarray(img)  # Convert NumPy array to PIL Image\n            img = self.transform(img)\n\n        return img\n\n# DataLoader Function with Model-Specific Transforms\ndef get_dataloader(hdf5_file, isic_ids, model_name, batch_size):\n    base_model = timm.create_model(model_name, pretrained=False, num_classes=1)\n    data_config = timm.data.resolve_model_data_config(base_model)\n    transform = timm.data.create_transform(**data_config, is_training=False)\n\n    dataset = CustomDataset(hdf5_file=hdf5_file, isic_ids=isic_ids, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    return dataloader\n\n# Function to generate features using the saved model\ndef generate_features(model_name, model_path, hdf5_file, isic_ids, df, config):\n    print(f\"Generating features using model: {model_name}\")\n\n    base_model = timm.create_model(model_name, pretrained=False, num_classes=1)\n\n    model = nn.Sequential(\n        base_model,\n        nn.Sigmoid()  # Sigmoid layer to output probabilities\n    )\n\n    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n    model.eval()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    dataloader = get_dataloader(hdf5_file, isic_ids, model_name, config['batch_size'])\n\n    predictions = []\n\n    with torch.no_grad():\n        for inputs in tqdm(dataloader, desc=f\"Processing {model_name}\"):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            predictions.extend(outputs.cpu().numpy().flatten())\n\n    df[model_name] = predictions\n\n    return df\n\n# Preprocessing Function for Filling Missing Values in Numeric Columns\ndef fill_na_with_median(df, num_cols):\n    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n    return df\n\n# Categorical Encoding Function\ndef encode_categorical(df, cat_cols, category_encoder=None):\n    if category_encoder is None:\n        category_encoder = OrdinalEncoder(\n            categories='auto',\n            dtype=int,\n            handle_unknown='use_encoded_value',\n            unknown_value=-2,\n            encoded_missing_value=-1,\n        )\n\n    X_cat = category_encoder.fit_transform(df[cat_cols])\n\n    for c, cat_col in enumerate(cat_cols):\n        df[cat_col] = X_cat[:, c]\n\n    return df, category_encoder\n\n# Function to load models\ndef load_models(model_paths, model_type):\n    models = []\n    if model_type == 'lightgbm':\n        import lightgbm as lgb\n        for path in model_paths:\n            model = lgb.Booster(model_file=path)\n            models.append(model)\n    return models\n\ndef predict_test_data():\n    df_test = pd.read_csv('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n\n    # Retain original isic_id for submission\n    original_isic_ids = df_test['isic_id'].copy()\n\n    # Drop unnecessary columns\n    df_test = df_test.drop(columns=columns_to_drop, errors='ignore')\n\n    # Fill missing values with median in numeric columns\n    df_test = fill_na_with_median(df_test, num_cols)\n\n    hdf5_file = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n    isic_ids = df_test['isic_id'].tolist()\n\n    # Load and apply feature generation models\n    for model_name, model_path in config['model_paths'].items():\n        df_test = generate_features(model_name, model_path, hdf5_file, isic_ids, df_test, config)\n\n    # Encode categorical columns\n    df_test, _ = encode_categorical(df_test, cat_cols)\n\n    # Fill remaining missing values with -1\n    df_test.fillna(-1, inplace=True)\n\n    # Ensure the column order matches the order that was used in the model training\n    feature_columns = [col for col in df_test.columns if col not in ['isic_id', 'patient_id']]\n    df_test = df_test[feature_columns]\n\n    # Load trained models\n    lgb_models = load_models(config['lightgbm_model_paths'], 'lightgbm')\n\n    # Make predictions with LightGBM models\n    lgb_preds = np.mean([model.predict(df_test) for model in lgb_models], axis=0)\n\n    # Ensemble the predictions\n    preds = lgb_preds\n\n    # Create submission DataFrame\n    submission = pd.DataFrame({\n        'isic_id': original_isic_ids,  # Use the original isic_id from test-metadata.csv\n        'target': preds\n    })\n\n    # Print the first 5 rows of the submission DataFrame\n    print(\"First 5 rows of the submission DataFrame:\")\n    print(submission.head())\n\n    # Save submission to CSV\n    submission.to_csv(config['submission_csv'], index=False)\n    print(f\"Submission saved to {config['submission_csv']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T08:33:09.997838Z","iopub.execute_input":"2024-09-06T08:33:09.998499Z","iopub.status.idle":"2024-09-06T08:33:10.024295Z","shell.execute_reply.started":"2024-09-06T08:33:09.998445Z","shell.execute_reply":"2024-09-06T08:33:10.023082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_test_data()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T08:33:10.026918Z","iopub.execute_input":"2024-09-06T08:33:10.027468Z","iopub.status.idle":"2024-09-06T08:33:11.068979Z","shell.execute_reply.started":"2024-09-06T08:33:10.027424Z","shell.execute_reply":"2024-09-06T08:33:11.067781Z"},"trusted":true},"execution_count":null,"outputs":[]}]}