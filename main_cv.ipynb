{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pandas wandb timm scikit-learn matplotlib lightgbm catboost",
   "id": "afb61eb65e11835c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import zipfile"
   ],
   "id": "1c1fe9de01abb63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zip_file_path_dataset = '/workspace/datasets/isic-2024-challenge.zip'\n",
    "extract_to_dir_dataset = '/workspace/datasets/isic-2024-challenge'\n",
    "os.makedirs(extract_to_dir_dataset, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file_path_dataset, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_dir_dataset)\n",
    "print(f'Files extracted to {extract_to_dir_dataset}')"
   ],
   "id": "fae225715c819ce1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zip_file_path_dataset = '/workspace/datasets/logs.zip'\n",
    "extract_to_dir_dataset = '/workspace/logs'\n",
    "os.makedirs(extract_to_dir_dataset, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file_path_dataset, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_dir_dataset)\n",
    "print(f'Files extracted to {extract_to_dir_dataset}')"
   ],
   "id": "db97e031b4e2c1bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zip_file_path_dataset = '/workspace/utils.zip'\n",
    "extract_to_dir_dataset = '/workspace/utils'\n",
    "os.makedirs(extract_to_dir_dataset, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_file_path_dataset, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_dir_dataset)\n",
    "print(f'Files extracted to {extract_to_dir_dataset}')"
   ],
   "id": "d938d8bc1c0dbca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from utils.lgbm_train import train_lightgbm_model  # Import LightGBM training function\n",
    "from utils.catb_train import train_catboost_model  # Import CatBoost training function\n",
    "\n",
    "import os\n",
    "import zipfile"
   ],
   "id": "e481ae071bd4961d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d367af866233f",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'model_paths': {\n",
    "        'efficientnet_b3.ra2_in1k': \"./logs/logs_effb3ra2in1k/epoch_19.pth\",\n",
    "        'selecsls42b.in1k': './logs/logs_selecsls42bin1k/epoch_35.pth',\n",
    "        'nextvit_small.bd_in1k_384' : \"./logs/logs_nextvit_small/nextvit_small.bd_in1k_384/epoch_9.pth\",\n",
    "    },\n",
    "    'feature_updated_csv': './datasets/isic-2024-challenge/feature_updated_dataset.csv',\n",
    "    'feature_engineered_csv': './datasets/isic-2024-challenge/feature_engineered_dataset.csv',\n",
    "    'post_processed_csv': './datasets/isic-2024-challenge/post_processed_dataset.csv',  # New entry for post-processed CSV\n",
    "    'lightgbm_config': {\n",
    "        'model_name': 'lightgbm',\n",
    "        'log_dir': './logs/lightgbm',\n",
    "        'n_splits': 5,\n",
    "        'seed': 42,\n",
    "        'display_feature_importance': True,\n",
    "        'feature_columns': [],\n",
    "        'target_column': 'target',\n",
    "        'group_column': 'patient_id',\n",
    "        'lgb_params': {\n",
    "            \"objective\": \"binary\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"n_estimators\": 200,\n",
    "            'learning_rate': 0.05,\n",
    "            'lambda_l1': 0.0004681884533249742,\n",
    "            'lambda_l2': 8.765240856362274,\n",
    "            'num_leaves': 136,\n",
    "            'feature_fraction': 0.5392005444882538,\n",
    "            'bagging_fraction': 0.9577412548866563,\n",
    "            'bagging_freq': 6,\n",
    "            'min_child_samples': 60,\n",
    "            \"device\": \"gpu\"\n",
    "        },\n",
    "        'save_best_model': True\n",
    "    },\n",
    "    'catboost_config': {\n",
    "        'model_name': 'catboost',\n",
    "        'log_dir': './logs/catboost',\n",
    "        'n_splits': 5,\n",
    "        'seed': 42,\n",
    "        'display_feature_importance': True,\n",
    "        'feature_columns': [],\n",
    "        'target_column': 'target',\n",
    "        'group_column': 'patient_id',\n",
    "        'cat_features': [],\n",
    "        'cb_params': {\n",
    "            'objective': 'Logloss',\n",
    "            \"iterations\": 400,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"max_depth\": 8,\n",
    "            \"l2_leaf_reg\": 5,\n",
    "            \"task_type\": \"GPU\",\n",
    "            \"verbose\": 0,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Numeric columns\n",
    "num_cols = [\n",
    "    'age_approx',\n",
    "    'clin_size_long_diam_mm',\n",
    "    'tbp_lv_A', 'tbp_lv_Aext',\n",
    "    'tbp_lv_B', 'tbp_lv_Bext',\n",
    "    'tbp_lv_C', 'tbp_lv_Cext',\n",
    "    'tbp_lv_H', 'tbp_lv_Hext',\n",
    "    'tbp_lv_L', 'tbp_lv_Lext',\n",
    "    'tbp_lv_areaMM2',\n",
    "    'tbp_lv_area_perim_ratio',\n",
    "    'tbp_lv_color_std_mean',\n",
    "    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL',\n",
    "    'tbp_lv_deltaLBnorm',\n",
    "    'tbp_lv_eccentricity',\n",
    "    'tbp_lv_minorAxisMM',\n",
    "    'tbp_lv_nevi_confidence',\n",
    "    'tbp_lv_norm_border',\n",
    "    'tbp_lv_norm_color',\n",
    "    'tbp_lv_perimeterMM',\n",
    "    'tbp_lv_radial_color_std_max',\n",
    "    'tbp_lv_stdL', 'tbp_lv_stdLExt',\n",
    "    'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
    "    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
    "]\n",
    "\n",
    "# Non-numeric data found in columns: ['anatom_site_general', 'image_type', 'attribution', 'copyright_license', 'combined_anatomical_site']\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\", \"anatom_site_general\",\"combined_anatomical_site\", ]\n",
    "\n",
    "# List of columns to drop based on comparison with test-metadata\n",
    "columns_to_drop = [\n",
    "    'iddx_3', 'iddx_2', 'iddx_5', 'iddx_full',\n",
    "    'tbp_lv_dnn_lesion_confidence', 'lesion_id',\n",
    "    'mel_mitotic_index', 'mel_thick_mm', 'iddx_1', 'iddx_4',\n",
    "    'image_type', 'attribution', 'copyright_license'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998751a7a407a581",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TRAIN CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013fab376421e92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def feature_engineering(df):\n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"] = np.sqrt(\n",
    "        df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2)\n",
    "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"consistency_symmetry_border\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (\n",
    "            df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n",
    "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    df[\"consistency_color\"] = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\n",
    "        \"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"] = np.sqrt(\n",
    "        (df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\n",
    "        \"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\n",
    "        \"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(\n",
    "        df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2)\n",
    "    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (\n",
    "            df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n",
    "    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"index_age_size_symmetry\"] = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6229d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class without storing image paths in DataFrame\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# DataLoader Function with Model-Specific Transforms\n",
    "def get_dataloader(image_paths, model_name, batch_size):\n",
    "    base_model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "    data_config = timm.data.resolve_model_data_config(base_model)\n",
    "    transform = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    dataset = CustomDataset(image_paths=image_paths, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Function to generate features using the saved model\n",
    "def generate_features(model_name, model_path, image_paths, df, config):\n",
    "    print(f\"Generating features using model: {model_name}\")\n",
    "\n",
    "    base_model = timm.create_model(model_name, pretrained=True, num_classes=1)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        base_model,\n",
    "        nn.Sigmoid()  # Sigmoid layer to output probabilities\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    dataloader = get_dataloader(image_paths, model_name, config['batch_size'])\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(dataloader, desc=f\"Processing {model_name}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "    df[model_name] = predictions\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Preprocessing Function for Filling Missing Values in Numeric Columns\n",
    "def fill_na_with_median(df, num_cols):\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "# Categorical Encoding Function\n",
    "def encode_categorical(df, cat_cols, category_encoder=None):\n",
    "    if category_encoder is None:\n",
    "        category_encoder = OrdinalEncoder(\n",
    "            categories='auto',\n",
    "            dtype=int,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-2,\n",
    "            encoded_missing_value=-1,\n",
    "        )\n",
    "\n",
    "    X_cat = category_encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "    for c, cat_col in enumerate(cat_cols):\n",
    "        df[cat_col] = X_cat[:, c]\n",
    "\n",
    "    return df, category_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e97b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if os.path.exists(config['feature_engineered_csv']):\n",
    "        print(f\"Feature engineered CSV already exists at: {config['feature_engineered_csv']}\")\n",
    "        df = pd.read_csv(config['feature_engineered_csv'])\n",
    "    else:\n",
    "        df = pd.read_csv('./datasets/isic-2024-challenge/train-metadata.csv')\n",
    "\n",
    "        # Drop unnecessary columns, including those missing in test-metadata\n",
    "        df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "        # Step 1: Fill missing values with median in numeric columns\n",
    "        df = fill_na_with_median(df, num_cols)\n",
    "\n",
    "        # Step 2: Apply feature engineering\n",
    "        df = feature_engineering(df)\n",
    "\n",
    "        # Step 3: Save the feature-engineered DataFrame\n",
    "        df.to_csv(config['feature_engineered_csv'], index=False)\n",
    "        print(f\"Saved DataFrame with feature engineering to {config['feature_engineered_csv']}\")\n",
    "\n",
    "    if os.path.exists(config['feature_updated_csv']):\n",
    "        print(f\"Feature updated CSV already exists at: {config['feature_updated_csv']}\")\n",
    "        df = pd.read_csv(config['feature_updated_csv'])\n",
    "    else:\n",
    "        image_paths = './datasets/isic-2024-challenge/train-image/image/' + df['isic_id'] + '.jpg'\n",
    "\n",
    "        for model_name, model_path in config['model_paths'].items():\n",
    "            df = generate_features(model_name, model_path, image_paths.tolist(), df, config)\n",
    "\n",
    "        # Step 4: Encode categorical columns\n",
    "        df, category_encoder = encode_categorical(df, cat_cols)\n",
    "\n",
    "        # Step 5: Save the updated DataFrame with generated features\n",
    "        df.to_csv(config['feature_updated_csv'], index=False)\n",
    "        print(f\"Saved DataFrame with model-generated features to {config['feature_updated_csv']}\")\n",
    "\n",
    "    # Check if post-processed CSV already exists\n",
    "    if os.path.exists(config['post_processed_csv']):\n",
    "        print(f\"Post-processed CSV already exists at: {config['post_processed_csv']}\")\n",
    "        df = pd.read_csv(config['post_processed_csv'])\n",
    "    else:\n",
    "        # Step 6: Post-process empty cells by filling them with -1\n",
    "        print(\"Post-processing the DataFrame by filling missing values with -1...\")\n",
    "        df.fillna(-1, inplace=True)\n",
    "\n",
    "        # Step 7: Save the post-engineered DataFrame\n",
    "        df.to_csv(config['post_processed_csv'], index=False)\n",
    "        print(f\"Saved post-engineered DataFrame to {config['post_processed_csv']}\")\n",
    "\n",
    "    # Now, proceed with training using the post-processed CSV\n",
    "    feature_columns = [col for col in df.columns if col not in ['isic_id', 'target', 'patient_id']]\n",
    "\n",
    "    if not feature_columns:\n",
    "        print(\"No feature columns identified. Please check the feature engineering step.\")\n",
    "    else:\n",
    "        print(f\"Feature columns identified: {feature_columns}\")\n",
    "\n",
    "    config['lightgbm_config']['feature_columns'] = feature_columns\n",
    "    config['catboost_config']['feature_columns'] = feature_columns\n",
    "\n",
    "    print(f\"Final feature columns: {config['lightgbm_config']['feature_columns']}\")\n",
    "\n",
    "    if not config['lightgbm_config']['feature_columns']:\n",
    "        raise ValueError(\"No feature columns set for LightGBM. Please check the configuration.\")\n",
    "\n",
    "    # Load the post-processed DataFrame for training\n",
    "    df = pd.read_csv(config['post_processed_csv'])\n",
    "\n",
    "    print(\"Starting LightGBM training...\")\n",
    "    lgbm_model_path = train_lightgbm_model(df, config['lightgbm_config'])\n",
    "    print(f\"LightGBM training completed. Models saved at: {lgbm_model_path}\")\n",
    "\n",
    "    print(\"Starting CatBoost training...\")\n",
    "    catboost_model_path = train_catboost_model(df, config['catboost_config'])\n",
    "    print(f\"CatBoost training completed. Models saved at: {catboost_model_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
