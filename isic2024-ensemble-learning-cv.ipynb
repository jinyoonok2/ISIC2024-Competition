{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 63056,
     "databundleVersionId": 9094797,
     "sourceType": "competition"
    },
    {
     "sourceId": 103033,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 68604,
     "modelId": 93771
    }
   ],
   "dockerImageVersionId": 30761,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport timm\nfrom tqdm import tqdm\nimport h5py\nfrom io import BytesIO\nimport torch\nimport torch.nn as nn",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-28T13:57:04.166826Z",
     "iopub.execute_input": "2024-08-28T13:57:04.167292Z",
     "iopub.status.idle": "2024-08-28T13:57:04.176034Z",
     "shell.execute_reply.started": "2024-08-28T13:57:04.167246Z",
     "shell.execute_reply": "2024-08-28T13:57:04.174569Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'model_paths': {\n",
    "        'selecsls42b.in1k': '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/17/_kaggle_models/sls/epoch_35.pth',\n",
    "        'efficientnet_b3.ra2_in1k': '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/17/_kaggle_models/eff3/epoch_19.pth',\n",
    "        'nextvit_small.bd_in1k_384' : \"/kaggle/input/isic2024-base-model-epoch3/pytorch/default/17/_kaggle_models/nexttf/epoch_9.pth\",\n",
    "    },\n",
    "    'lightgbm_model_paths': ['/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/lightgbm/fold_1/best_model.txt',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/lightgbm/fold_2/best_model.txt',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/lightgbm/fold_3/best_model.txt',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/lightgbm/fold_4/best_model.txt',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/lightgbm/fold_5/best_model.txt'],\n",
    "    'catboost_model_paths': ['/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/catboost/fold_1/best_model.cbm',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/catboost/fold_2/best_model.cbm',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/catboost/fold_3/best_model.cbm',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/catboost/fold_4/best_model.cbm',\n",
    "                             '/kaggle/input/isic2024-base-model-epoch3/pytorch/default/15/catboost/fold_5/best_model.cbm'],\n",
    "    'submission_csv': 'submission.csv',\n",
    "}\n",
    "\n",
    "# Numeric columns\n",
    "num_cols = [\n",
    "    'age_approx',\n",
    "    'clin_size_long_diam_mm',\n",
    "    'tbp_lv_A', 'tbp_lv_Aext',\n",
    "    'tbp_lv_B', 'tbp_lv_Bext',\n",
    "    'tbp_lv_C', 'tbp_lv_Cext',\n",
    "    'tbp_lv_H', 'tbp_lv_Hext',\n",
    "    'tbp_lv_L', 'tbp_lv_Lext',\n",
    "    'tbp_lv_areaMM2',\n",
    "    'tbp_lv_area_perim_ratio',\n",
    "    'tbp_lv_color_std_mean',\n",
    "    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL',\n",
    "    'tbp_lv_deltaLBnorm',\n",
    "    'tbp_lv_eccentricity',\n",
    "    'tbp_lv_minorAxisMM',\n",
    "    'tbp_lv_nevi_confidence',\n",
    "    'tbp_lv_norm_border',\n",
    "    'tbp_lv_norm_color',\n",
    "    'tbp_lv_perimeterMM',\n",
    "    'tbp_lv_radial_color_std_max',\n",
    "    'tbp_lv_stdL', 'tbp_lv_stdLExt',\n",
    "    'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
    "    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
    "]\n",
    "\n",
    "# Non-numeric data found in columns: ['anatom_site_general', 'image_type', 'attribution', 'copyright_license', 'combined_anatomical_site']\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\", \"anatom_site_general\",\"combined_anatomical_site\", ]\n",
    "\n",
    "# List of columns to drop based on comparison with test-metadata\n",
    "columns_to_drop = [\n",
    "    'iddx_3', 'iddx_2', 'iddx_5', 'iddx_full',\n",
    "    'tbp_lv_dnn_lesion_confidence', 'lesion_id',\n",
    "    'mel_mitotic_index', 'mel_thick_mm', 'iddx_1', 'iddx_4',\n",
    "    'image_type', 'attribution', 'copyright_license'\n",
    "]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-28T13:57:04.178056Z",
     "iopub.execute_input": "2024-08-28T13:57:04.178628Z",
     "iopub.status.idle": "2024-08-28T13:57:04.197577Z",
     "shell.execute_reply.started": "2024-08-28T13:57:04.178558Z",
     "shell.execute_reply": "2024-08-28T13:57:04.196061Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Custom Dataset Class for HDF5 Images\nclass CustomDataset(Dataset):\n    def __init__(self, hdf5_file, isic_ids, transform=None):\n        self.hdf5_file = hdf5_file\n        self.isic_ids = isic_ids\n        self.transform = transform\n        self.fp_hdf = h5py.File(hdf5_file, mode=\"r\")\n\n    def __len__(self):\n        return len(self.isic_ids)\n\n    def __getitem__(self, idx):\n        isic_id = self.isic_ids[idx]\n        # Corrected image loading using BytesIO\n        img = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n\n        if self.transform:\n            img = Image.fromarray(img)  # Convert NumPy array to PIL Image\n            img = self.transform(img)\n\n        return img\n\n# DataLoader Function with Model-Specific Transforms\ndef get_dataloader(hdf5_file, isic_ids, model_name, batch_size):\n    base_model = timm.create_model(model_name, pretrained=False, num_classes=1)\n    data_config = timm.data.resolve_model_data_config(base_model)\n    transform = timm.data.create_transform(**data_config, is_training=False)\n\n    dataset = CustomDataset(hdf5_file=hdf5_file, isic_ids=isic_ids, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    return dataloader\n\n# Function to generate features using the saved model\ndef generate_features(model_name, model_path, hdf5_file, isic_ids, df, config):\n    print(f\"Generating features using model: {model_name}\")\n\n    base_model = timm.create_model(model_name, pretrained=False, num_classes=1)\n\n    model = nn.Sequential(\n        base_model,\n        nn.Sigmoid()  # Sigmoid layer to output probabilities\n    )\n\n    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n    model.eval()\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    dataloader = get_dataloader(hdf5_file, isic_ids, model_name, config['batch_size'])\n\n    predictions = []\n\n    with torch.no_grad():\n        for inputs in tqdm(dataloader, desc=f\"Processing {model_name}\"):\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            predictions.extend(outputs.cpu().numpy().flatten())\n\n    df[model_name] = predictions\n\n    return df\n\n# Preprocessing Function for Filling Missing Values in Numeric Columns\ndef fill_na_with_median(df, num_cols):\n    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n    return df\n\n# Categorical Encoding Function\ndef encode_categorical(df, cat_cols, category_encoder=None):\n    if category_encoder is None:\n        category_encoder = OrdinalEncoder(\n            categories='auto',\n            dtype=int,\n            handle_unknown='use_encoded_value',\n            unknown_value=-2,\n            encoded_missing_value=-1,\n        )\n\n    X_cat = category_encoder.fit_transform(df[cat_cols])\n\n    for c, cat_col in enumerate(cat_cols):\n        df[cat_col] = X_cat[:, c]\n\n    return df, category_encoder\n\n# Function to load models\ndef load_models(model_paths, model_type):\n    models = []\n    if model_type == 'lightgbm':\n        import lightgbm as lgb\n        for path in model_paths:\n            model = lgb.Booster(model_file=path)\n            models.append(model)\n    elif model_type == 'catboost':\n        from catboost import CatBoostClassifier\n        for path in model_paths:\n            model = CatBoostClassifier()\n            model.load_model(path)\n            models.append(model)\n    return models\n\ndef predict_test_data():\n    df_test = pd.read_csv('/kaggle/input/isic-2024-challenge/test-metadata.csv')\n\n    # Retain original isic_id for submission\n    original_isic_ids = df_test['isic_id'].copy()\n\n    # Drop unnecessary columns\n    df_test = df_test.drop(columns=columns_to_drop, errors='ignore')\n\n    # Fill missing values with median in numeric columns\n    df_test = fill_na_with_median(df_test, num_cols)\n\n    # Apply feature engineering\n    df_test = feature_engineering(df_test)\n\n    hdf5_file = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n    isic_ids = df_test['isic_id'].tolist()\n\n    # Load and apply feature generation models\n    for model_name, model_path in config['model_paths'].items():\n        df_test = generate_features(model_name, model_path, hdf5_file, isic_ids, df_test, config)\n\n    # Encode categorical columns\n    df_test, _ = encode_categorical(df_test, cat_cols)\n\n    # Fill remaining missing values with -1\n    df_test.fillna(-1, inplace=True)\n\n    # Ensure the column order matches the order that was used in the model training\n    feature_columns = [col for col in df_test.columns if col not in ['isic_id', 'patient_id']]\n    df_test = df_test[feature_columns]\n\n    # Load trained models\n    lgb_models = load_models(config['lightgbm_model_paths'], 'lightgbm')\n    cb_models = load_models(config['catboost_model_paths'], 'catboost')\n\n    # Make predictions with LightGBM models\n    lgb_preds = np.mean([model.predict(df_test) for model in lgb_models], axis=0)\n\n    # Make predictions with CatBoost models\n    cb_preds = np.mean([model.predict_proba(df_test)[:, 1] for model in cb_models], axis=0)\n\n    # Ensemble the predictions\n    preds = lgb_preds * 0.315 + cb_preds * 0.685\n\n    # Create submission DataFrame\n    submission = pd.DataFrame({\n        'isic_id': original_isic_ids,  # Use the original isic_id from test-metadata.csv\n        'target': preds\n    })\n\n    # Print the first 5 rows of the submission DataFrame\n    print(\"First 5 rows of the submission DataFrame:\")\n    print(submission.head())\n\n    # Save submission to CSV\n    submission.to_csv(config['submission_csv'], index=False)\n    print(f\"Submission saved to {config['submission_csv']}\")\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-28T13:57:04.200015Z",
     "iopub.execute_input": "2024-08-28T13:57:04.200488Z",
     "iopub.status.idle": "2024-08-28T13:57:04.236963Z",
     "shell.execute_reply.started": "2024-08-28T13:57:04.200436Z",
     "shell.execute_reply": "2024-08-28T13:57:04.235747Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Feature Engineering Function\ndef feature_engineering(df):\n    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n    df[\"lesion_color_difference\"] = np.sqrt(\n        df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2)\n    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n    df[\"consistency_symmetry_border\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (\n            df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n    df[\"consistency_color\"] = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\n        \"tbp_lv_deltaLBnorm\"]\n    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n    df[\"std_dev_contrast\"] = np.sqrt(\n        (df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\n        \"tbp_lv_symm_2axis\"]) / 3\n    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\n        \"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(\n        df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2)\n    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (\n            df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n    df[\"index_age_size_symmetry\"] = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n\n    return df",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-28T13:57:04.324909Z",
     "iopub.execute_input": "2024-08-28T13:57:04.325785Z",
     "iopub.status.idle": "2024-08-28T13:57:04.351216Z",
     "shell.execute_reply.started": "2024-08-28T13:57:04.325729Z",
     "shell.execute_reply": "2024-08-28T13:57:04.350042Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "predict_test_data()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-28T13:57:04.353402Z",
     "iopub.execute_input": "2024-08-28T13:57:04.353802Z",
     "iopub.status.idle": "2024-08-28T13:57:07.491554Z",
     "shell.execute_reply.started": "2024-08-28T13:57:04.353748Z",
     "shell.execute_reply": "2024-08-28T13:57:07.490390Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "Generating features using model: selecsls42b.in1k\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_162/2273659417.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\nProcessing selecsls42b.in1k: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Generating features using model: efficientnet_b3.ra2_in1k\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_162/2273659417.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\nProcessing efficientnet_b3.ra2_in1k: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[LightGBM] [Warning] Ignoring unrecognized parameter 'early_stopping_min_delta' found in model string.\n[LightGBM] [Warning] Ignoring unrecognized parameter 'early_stopping_min_delta' found in model string.\n[LightGBM] [Warning] Ignoring unrecognized parameter 'early_stopping_min_delta' found in model string.\n[LightGBM] [Warning] Ignoring unrecognized parameter 'early_stopping_min_delta' found in model string.\n[LightGBM] [Warning] Ignoring unrecognized parameter 'early_stopping_min_delta' found in model string.\nFirst 5 rows of the submission DataFrame:\n        isic_id    target\n0  ISIC_0015657  0.000065\n1  ISIC_0015729  0.000077\n2  ISIC_0015740  0.000072\nSubmission saved to submission.csv\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
